{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5878857-2257-40a8-9c79-9d57b50047cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.4.2 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (3.4.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from pyspark==3.4.2) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc6d5d1-70af-47ce-8129-731035913b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minio in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (7.2.7)\n",
      "Requirement already satisfied: certifi in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from minio) (2024.7.4)\n",
      "Requirement already satisfied: urllib3 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from minio) (2.2.2)\n",
      "Requirement already satisfied: pycryptodome in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from minio) (3.20.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from minio) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from minio) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9aef6a-157f-4e54-bee7-642b38391de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delta-spark==2.4.0 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: pyspark<3.5.0,>=3.4.0 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from delta-spark==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from delta-spark==2.4.0) (8.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from importlib-metadata>=1.0.0->delta-spark==2.4.0) (3.19.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages (from pyspark<3.5.0,>=3.4.0->delta-spark==2.4.0) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install delta-spark==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f1fb93-d5ef-4a8f-b9e2-6a891863f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "from minio import Minio\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ea502d-c1e5-45a9-9325-d1f533b69f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 20:49:51 WARN Utils: Your hostname, DESKTOP-CV9TLA8 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/08/24 20:49:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/hacs/.cache/pypoetry/virtualenvs/pyspark-delta-gPM1PAZH-py3.10/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hacs/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hacs/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a0cb636f-0644-4e0f-9775-f84f207f727a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 165ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a0cb636f-0644-4e0f-9775-f84f207f727a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "24/08/24 20:49:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\").appName(\"csvToParquet\")\n",
    "    #HADOOP\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    #DELTA\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.jars\", \"jars/aws-java-sdk-bundle-1.11.1026.jar, \\\n",
    "            jars/hadoop-aws-3.2.0.jar\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970b86ee-ce00-4329-9406-fbb2f79ffefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=Minio(\"localhost:9000\",\n",
    "             access_key=\"minioadmin\",\n",
    "             secret_key=\"minioadmin\",\n",
    "             secure=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d0aa29-31f4-42af-ad39-2c1308a08f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects=client.list_objects('raw', prefix='CAPES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410ff462-641b-4973-8ea8-32d0b88848fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects=client.list_objects('raw', prefix='CAPES/')\n",
    "csvs = []\n",
    "for object in objects:\n",
    "    csvs.append(object.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5ce3ed-fca1-4261-b053-0ac8afcd8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66479d4-8350-457c-8b69-eb60c31153c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalslist(df1, df2):\n",
    "    return list(set(df1.columns).intersection(set(df2.columns)))\n",
    "    \n",
    "def dfjoin(dataframe1, dataframe2, columnjoin, typejoin):\n",
    "    \n",
    "    equals = equalslist(dataframe1,dataframe2)\n",
    "    equals.remove(columnjoin)\n",
    "    dataframe3 = dataframe2\n",
    "    for column in equals:\n",
    "        dataframe3 = dataframe3.drop(column)\n",
    "        \n",
    "    dataframe_join = dataframe1.join(dataframe3, columnjoin, typejoin)\n",
    "    dataframe_join = dataframe_join.dropna(subset=[columnjoin])\n",
    "    return dataframe_join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde116eb-c10e-4f29-b4d8-a06ca8d37866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - CAPES/2021-a-2024-autor-da-producao-intelectual-de-programas-de-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "1 - CAPES/2021-a-2024-catalogo-de-teses-e-dissertacoes-brasil.csv\n",
      "2 - CAPES/2021-a-2024-cursos-da-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "3 - CAPES/2021-a-2024-detalhes-da-producao-intelectual-bibliografica-de-programas-de-pos-graduacao.csv\n",
      "4 - CAPES/2021-a-2024-detalhes-da-producao-intelectual-tecnica-de-programas-de-pos-graduacao-stricto-sensu.csv\n",
      "5 - CAPES/2021-a-2024-discentes-da-pos-graduacao-stricto-sensu-do-brasil.csv\n",
      "6 - CAPES/2021-a-2024-docentes-da-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "7 - CAPES/2021-a-2024-financiadores-de-projetos-dos-programas-de-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "8 - CAPES/2021-a-2024-membros-de-projetos-dos-programas-de-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "9 - CAPES/2021-a-2024-producao-intelectual-de-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "10 - CAPES/2021-a-2024-programas-da-pos-graduacao-stricto-sensu-no-brasil.csv\n",
      "11 - CAPES/2021-a-2024-projetos-dos-programas-de-pos-graduacao-stricto-sensu-no-brasil.csv\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for csv in csvs:\n",
    "    print(f'{count} - {csv}')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5951cf16-2425-4cdf-9010-a613af9f0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 20:49:54 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "autores = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[0]}')\n",
    "teses = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[1]}')\n",
    "cursos = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[2]}')\n",
    "bibliografica = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[3]}')\n",
    "tecnica = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[4]}')\n",
    "discentes = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[5]}')\n",
    "docentes = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[6]}')\n",
    "financiadores = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[7]}')\n",
    "membros = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[8]}')\n",
    "producoes = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[9]}')\n",
    "programas = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[10]}')\n",
    "projetos = spark.read.format('csv').option('header', 'true').option('sep', ';').load(f's3a://{bucket_name}/{csvs[11]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2c7d576-5dec-4c09-8ebe-3bd942cd2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "programa_curso = dfjoin(cursos, programas, \"CD_PROGRAMA_IES\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1923b1a0-aa3e-4368-a13d-746fff761b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "projetos_membros = dfjoin(projetos, membros, \"ID_PROJETO\", 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e6bd1bb-45de-4965-a0fe-d887b79bb17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:=========>                                              (2 + 10) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|NM_PRODUCAO|ID_PROJETO|\n",
      "+-----------+----------+\n",
      "|       null|    100008|\n",
      "|       null|    100029|\n",
      "|       null|    100029|\n",
      "|       null|    100029|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100031|\n",
      "|       null|    100046|\n",
      "|       null|    100046|\n",
      "|       null|    100046|\n",
      "|       null|    100081|\n",
      "|       null|    100081|\n",
      "|       null|    100081|\n",
      "|       null|    100081|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "producoes_projetos = dfjoin(projetos_membros, producoes, \"ID_PROJETO\", \"full\")\n",
    "producoes_projetos.select(\"NM_PRODUCAO\", \"ID_PROJETO\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "862dee31-720e-4e2f-9727-7580a2e03578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1021410"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producoes_projetos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b6db219-2259-43aa-a53f-db812c822903",
   "metadata": {},
   "outputs": [],
   "source": [
    "producoes_projetos = dfjoin(producoes_projetos, financiadores, \"ID_PROJETO\", 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc25c53d-d26d-49cf-af03-d798a90dd088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1658551"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producoes_projetos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea3988-47e9-4c3f-ba27-913a5fcb3c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
